{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 3: Social Networking & Computational Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggleNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Collecting certifi>=2023.7.22\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from kaggle) (2.24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from kaggle) (4.50.2)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from kaggle) (1.25.11)\n",
      "Requirement already satisfied: bleach in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from kaggle) (3.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: webencodings in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from bleach->kaggle) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\aparna\\anaconda3\\lib\\site-packages (from packaging->bleach->kaggle) (2.4.7)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105795 sha256=d9781eb6b1d05d41e8c41b020d780dbaa946f08dd33c2f7913a6f884d4071281\n",
      "  Stored in directory: c:\\users\\aparna\\appdata\\local\\pip\\cache\\wheels\\a5\\6f\\7b\\837915771e94e181fa3052822926444e34f725ca38e70be77e\n",
      "Successfully built kaggle\n",
      "Installing collected packages: certifi, text-unidecode, python-slugify, kaggle\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.6.20\n",
      "    Uninstalling certifi-2020.6.20:\n",
      "      Successfully uninstalled certifi-2020.6.20\n",
      "Successfully installed certifi-2024.12.14 kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set Kaggle API key \n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"*****\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"********\"\n",
    "\n",
    "# Import Kaggle API\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Initialize the API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download a dataset\n",
    "dataset_name = \"mrmorj/hate-speech-and-offensive-language-dataset\"\n",
    "api.dataset_download_files(dataset_name, path=\"./data\", unzip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_offensive_language_dataset(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    dataset.columns = [\"sno\", \"count\", \"hate_speech\",\"offensive_language\",\"neither\",\"class\",\"tweet\"]\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sno  count  hate_speech  offensive_language  neither  class  \\\n",
      "0    0      3            0                   0        3      2   \n",
      "1    1      3            0                   3        0      1   \n",
      "2    2      3            0                   3        0      1   \n",
      "3    3      3            0                   2        1      1   \n",
      "4    4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'C:/Users/Aparna/Desktop/UC/MSAI/spring 2025/MSAI532NLP/week-4/Assignment-3/data/labeled_data.csv'\n",
    "\n",
    "# Load the dataset\n",
    "offensive_language_data = load_offensive_language_dataset(dataset_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(offensive_language_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
